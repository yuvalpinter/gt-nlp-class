{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 3: Structured Perceptron\n",
    "====================\n",
    "\n",
    "In this problem set, you will implement a sequence labeling algorithm that is near state-of-the-art: structured perceptron. To do this, you will use several functions that you have written earlier, especially Viterbi and averaged perceptron.\n",
    "\n",
    "The problem set is designed to highlight the connection between structured perceptron and classification-based tagging. You will first write most of the pieces that you need while working in the framework of classification-based tagging. Your implementation will take various tagging algorithms as arguments, including both one-word-at-a-time classification based tagging, and Viterbi sequence labeling.\n",
    "\n",
    "One of the main reasons to prefer perceptron over hidden Markov models is the ability to use rich, overlapping features. You will design several feature functions throughout the assignment.\n",
    "\n",
    "Because structure perceptron is slower to train than the hidden Markov model, we will use smaller datasets in this assignment, focusing on sentences that contain the most common POS tags in English and Japanese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import preproc, tagger_base, scorer \n",
    "from gtnlplib import features, viterbi, constants, structure_perceptron\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tags: set([u'ADV', u'NOUN', u'ADP', u'PRON', u'PROPN', u'DET', u'PUNCT', u'VERB', u'AUX', u'ADJ'])\n",
      "Japanese tags: set([u'ADV', u'NOUN', u'PRON', u'DET', u'PUNCT', u'VERB', u'NUM', u'ADJ'])\n"
     ]
    }
   ],
   "source": [
    "## Demo\n",
    "## NOTE! These datafiles are different than in pset2. Don't copy over constants.py from that pset.\n",
    "all_tags = set()\n",
    "for i,(words, tags) in enumerate(preproc.conll_seq_generator(constants.TRAIN_FILE,max_insts=100000)):\n",
    "    for tag in tags:\n",
    "        all_tags.add(tag)\n",
    "print(\"English tags: {}\".format(all_tags))\n",
    "\n",
    "all_tags_ja = set()\n",
    "for i,(words, tags) in enumerate(preproc.conll_seq_generator(constants.JA_TRAIN_FILE,max_insts=100000)):\n",
    "    for tag in tags:\n",
    "        all_tags_ja.add(tag)\n",
    "print(\"Japanese tags: {}\".format(all_tags_ja))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tagging as discriminative classification\n",
    "\n",
    "In pset 2, you performed part-of-speech tagging as generative classification, using Naive Bayes. Now you will perform discriminative classification, using average perceptron.\n",
    "\n",
    "In this section, we are only doing classification-based tagging, but we will write the code in a way that generalizes to Viterbi-based structure prediction. This means that all features are of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.1** Implement `features.word_feats` to output features that are tuples `(y,constants.CURR_WORD_FEAT,w[m])` and `(y,constants.OFFSET)`.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--CURR-WORD--', 'man'): 1.0}\n",
      "{('VERB', '--CURR-WORD--', 'the'): 1.0, ('VERB', '**OFFSET**'): 1.0}\n",
      "{('NOUN', '**OFFSET**'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(features.word_feats(['The','old','man','the','boat'],'NOUN','ADJ',2))\n",
    "print(features.word_feats(['The','old','man','the','boat'],'VERB','NOUN',3))\n",
    "# note that we may need to handle m >= len(tokens)\n",
    "print(features.word_feats(['The','old','man','the','boat'],'NOUN','ADJ',5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.2** Reimplement `tagger_base.classifier_tagger` as follows:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- List of tokens to tag\n",
    "- Feature function, of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$\n",
    "- Defaultdict of weights\n",
    "- List of all candidate tags\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- List of predicted tags\n",
    "- Score of predicted tag sequence $\\theta \\cdot f(\\boldsymbol{w},\\boldsymbol{y})$\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_clf_hand = defaultdict(float,\n",
    "                             {('NOUN',constants.OFFSET):0.1,\n",
    "                              ('PRON',constants.CURR_WORD_FEAT,'They'):1,\n",
    "                              ('PRON',constants.CURR_WORD_FEAT,'can'):-1,\n",
    "                              ('NOUN',constants.CURR_WORD_FEAT,'fish'):1,\n",
    "                              ('VERB',constants.CURR_WORD_FEAT,'fish'):0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'can', 'fish']\n"
     ]
    }
   ],
   "source": [
    "w = 'They can fish'.split()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'PRON', u'NOUN', u'NOUN'], 2.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.classifier_tagger(w,features.word_feats,theta_clf_hand,all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.3** The perceptron update requires computing the difference\n",
    "\n",
    "\\begin{align}\n",
    "& f(\\boldsymbol{w},\\boldsymbol{y}) - f(\\boldsymbol{w},\\hat{\\boldsymbol{y}})\\\\\n",
    "= & \\sum_{m=1}^M f(\\boldsymbol{w},y_m,y_{m-1},m) - f(\\boldsymbol{w},\\hat{y}_m,\\hat{y}_{m-1},m)\n",
    "\\end{align}\n",
    "\n",
    "Implement `tagger_base.compute_features` to compute $f(\\boldsymbol{w},\\boldsymbol{y})$, with the following arguments:\n",
    "\n",
    "- A list of words\n",
    "- A list of tags\n",
    "- A feature function, of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$.\n",
    "\n",
    "The output should be a dict of features and counts.\n",
    "\n",
    "*Boundary cases*: \n",
    "\n",
    "- When $m=0$, use the special case $y_{-1} = \\text{START}$, using `constants.START_TAG`. *Your current feature function will not test this, because it ignores $y_{m-1}$, but we will test it later*.\n",
    "- When $m=M$, use the special case $y_M = \\text{STOP}$, using `constants.END_TAG`. \n",
    "\n",
    "These boundary cases will be important when you incorporate Viterbi tagging.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('--END--', '**OFFSET**'): 1.0,\n",
       "             ('DET', '**OFFSET**'): 2.0,\n",
       "             ('DET', '--CURR-WORD--', 'the'): 2.0,\n",
       "             ('NOUN', '**OFFSET**'): 2.0,\n",
       "             ('NOUN', '--CURR-WORD--', 'boat'): 1.0,\n",
       "             ('NOUN', '--CURR-WORD--', 'old'): 1.0,\n",
       "             ('VERB', '**OFFSET**'): 1.0,\n",
       "             ('VERB', '--CURR-WORD--', 'man'): 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.compute_features('the old man the boat'.split(),\n",
    "                            ['DET','NOUN','VERB','DET','NOUN'],\n",
    "                            features.word_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.4**\n",
    "\n",
    "Now you can implement the function `structure_perceptron.sp_update`. \n",
    "\n",
    "This will be very similar to your implementation of `perceptron.perceptron_update` in pset 1, but instead of calling `clf_base.predict`, you should call a function `tagger` which is passed in as an argument.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'PRON', u'NOUN', u'NOUN'], 2.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.classifier_tagger('They can fish'.split(),\n",
    "                             features.word_feats,\n",
    "                             theta_clf_hand,\n",
    "                             all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update = structure_perceptron.sp_update('They can fish'.split(),\n",
    "                               ['PRON','AUX','VERB'],\n",
    "                               theta_clf_hand,\n",
    "                               features.word_feats,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'NOUN', '**OFFSET**'), -2.0)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('VERB', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for key,val in update.iteritems():\n",
    "    if val != 0:\n",
    "        print(key,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.5**\n",
    "\n",
    "You are now ready to implement `structure_perceptron.estimate_perceptron`.\n",
    "\n",
    "Your implementation will be nearly identical to `perceptron.estimate_perceptron`, except for two things:\n",
    "\n",
    "- The input is now a list of (token-list, tag-list) tuples\n",
    "- Instead of calling `perceptron.perceptron_update`, you will call `structure_perceptron.sp_update`.\n",
    "\n",
    "Other aspects of the implementation, such as weight averaging, should be identical.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "reload(tagger_base)\n",
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_data = [('They can fish'.split(),['PRON','AUX','VERB']),\n",
    "            ('the old man the boat'.split(),['DET','NOUN','VERB','DET','NOUN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst,_ = structure_perceptron.estimate_perceptron(toy_data[:1],\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                1,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--CURR-WORD--', 'They'): 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.word_feats(toy_data[0][0],'NOUN','IGNORE',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "(('PRON', '--CURR-WORD--', 'They'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -2.999)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "(('PRON', '**OFFSET**'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('VERB', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy_one_inst.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst,_ = structure_perceptron.estimate_perceptron(toy_data[:1],\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                10,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "(('PRON', '--CURR-WORD--', 'They'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -2.999)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "(('PRON', '**OFFSET**'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('VERB', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy_one_inst.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                     features.word_feats,\n",
    "                                                     tagger_base.classifier_tagger,\n",
    "                                                     1, all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'PRON', '--CURR-WORD--', 'boat'), -0.5)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -1.999)\n",
      "(('NOUN', '--CURR-WORD--', 'old'), 0.5)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "(('PRON', '**OFFSET**'), -1.5)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('VERB', '**OFFSET**'), 1.5)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'old'), -0.5)\n",
      "(('PRON', '--CURR-WORD--', 'They'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'man'), 0.5)\n",
      "(('NOUN', '--CURR-WORD--', 'boat'), 0.5)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'the'), -1.0)\n",
      "(('DET', '--CURR-WORD--', 'the'), 1.0)\n",
      "(('DET', '**OFFSET**'), 1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'man'), -0.5)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 1.6 ** Let's train this tagger and evaluate it.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = [inst for inst in preproc.conll_seq_generator(constants.TRAIN_FILE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3531"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes 30 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_avp,theta_hist = structure_perceptron.estimate_perceptron(training_set,\n",
    "                                                       features.word_feats,\n",
    "                                                       tagger_base.classifier_tagger,\n",
    "                                                       20,\n",
    "                                                       all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129496402877698"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-020d7712d1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-te.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Yuval\\git\\gt-nlp-class\\psets\\ps3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this line\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how accuracy improved over training. \n",
    "You can use this function elsewhere in the notebook if you'd like to see the progress of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b229b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagger_base.plot_learning_curve(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_hist,\n",
    "                               all_tags);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These accuracies are not directly comparable with your HMM accuracies from pset2, since we are using a different dataset.\n",
    "\n",
    "Let's see how many features are active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active features: 19265\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of active features: %d\"%len([val for val in theta_avp.values() if val != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.7** Now try it on Japanese. \n",
    "\n",
    "(*0.5 points for 4650 / 0.25 points for 7650*)\n",
    "\n",
    "As before, 4650 students can opt in to 7650 grading by doing the 7650 problems.\n",
    "\n",
    "Please set the `GRADING` variable in `constants.py` to the appropriate grading scheme. Note that CS7650 students must be graded by the CS7650 rubric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_ja = [inst for inst in preproc.conll_seq_generator(constants.JA_TRAIN_FILE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes approximately 40 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_avp_ja,theta_hist_ja =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.790288213524728"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.8 (for 7650)** As you can see from the cells here, this tagging model is less accurate for Japanese than it is for English. Why might that be? (I'm looking for an explanation that is based on quantitative facts about the datasets.) Put your answer in `text-answers.md`.\n",
    "\n",
    "(*0.5 points for 7650, optional for 4650*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active features: 38401\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of active features: %d\"%len([val for val in theta_avp_ja.values() if val != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3531, 2655)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set), len(training_set_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Better features\n",
    "\n",
    "One simple way to improve tagging is to add better features to the classification-based tagger. \n",
    "\n",
    "**Deliverable 2.1** Let's start by adding features that include the final two characters of each word as an additional, suffix feature. Do this by implementing `word_suff_features` in `features.py`.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(constants)\n",
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('DET', '--CURR-WORD--', 'The'): 1.0, ('DET', '**OFFSET**'): 1.0, ('DET', '--SUFFIX--', 'he'): 1.0}\n",
      "{('NOUN', '--SUFFIX--', 'ld'): 1.0, ('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--CURR-WORD--', 'old'): 1.0}\n",
      "{('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--SUFFIX--', 'a'): 1.0, ('NOUN', '--CURR-WORD--', 'a'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(features.word_suff_feats(['The','old','man','a','boat'],'DET','ADJ',0))\n",
    "print(features.word_suff_feats(['The','old','man','a','boat'],'NOUN','DET',1))\n",
    "print(features.word_suff_feats(['The','old','man','a','boat'],'NOUN','ADJ',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.2** Let's see whether this improves accuracy.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650. Includes both English and Japanese evaluations.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes 50 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_suff_avp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_suff_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8439248601119105"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you cannot run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-suff-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 3% better than the word-only feature set! That's pretty good for adding a single feature template. Now let's try Japanese. \n",
    "\n",
    "The cell below takes 45 seconds to execute on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_suff_avp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_suff_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8816866659190311"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-suff.ja.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10% better on Japanese! Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp_ja,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-129fe741bb06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJA_TEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-suff-te.ja.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Yuval\\git\\gt-nlp-class\\psets\\ps3\\gtnlplib\\scorer.pyc\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/ja-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-suff-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.3 (7650)** Briefly explain why you think suffix features are so helpful in Japanese. No prior Japanese knowledge is assumed! You may want to look at the raw data, and consult some resources about Japanese that you can find from a quick Google search. Put your answer in `text-answers.md`.\n",
    "\n",
    "(*0.5 points for 7650, optional for 4650*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.4** Now implement word neighbor features. These are features that should link a given tag to the words than come before and after it. Implement this function in `features.word_neighbor_feats`, and make sure it gives the same results as in the example cell below. Pay attention to the boundary case at the end. See `constants.PRE_START_TOKEN` and `constants.POST_END_TOKEN`.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(constants)\n",
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TAG', '--CURR-WORD--', 'The'): 1.0\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--PREV-WORD--', '[[START]]'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'old'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'man'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'The'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'old'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'a'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'man'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'old'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'a'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'man'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'boat'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--NEXT-WORD--', '[[END]]'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'a'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'boat'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'boat'): 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in xrange(6):\n",
    "    feats = features.word_neighbor_feats(['The','old','man','a','boat'],'TAG','IGNORE',m)\n",
    "    for feat,count in feats.iteritems():\n",
    "        print('{}: {}'.format(feat,count))\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.5** Let's try it, in both English and Japanese.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650*)\n",
    "\n",
    "The code below takes 60 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_neighbor_avp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_neighbor_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577138289368506"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_neighbor_feats,\n",
    "                               theta_neighbor_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-neighbor.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better for English than the suffix features! Let's try Japanese.\n",
    "\n",
    "The code below takes 60 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_neighbor_avp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_neighbor_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8020634742626443"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_neighbor_feats,\n",
    "                               theta_neighbor_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-neighbor.ja.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neighbor features don't help nearly as much in Japanese, compared to the impact they make in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAKEOFF #1\n",
    "\n",
    "**Deliverable 2.6** Implement the best features that you can for English and Japanese.\n",
    "You can use the same features for each, or you can use different features.\n",
    "You can also train the model longer, if you think that will help.\n",
    "\n",
    "Make sure to save the output in the following files:\n",
    "\n",
    "- **English dev**: `avp-best.preds`\n",
    "- **English test**: `avp-best-te.preds`\n",
    "- **Japanese dev**: `avp-best.ja.preds`\n",
    "- **Japanese test**: `avp-best-te.ja.preds`\n",
    "\n",
    "Grading:\n",
    "- Full credit (0.5 pts) for **88%** accuracy on English dev set, half credit (0.25 pts) for **87%** dev set accuracy.\n",
    "- Full credit (0.5 pts) for **90%** accuracy on Japanese dev set, half credit (0.25 pts) for **89%** dev set accuracy.\n",
    "- +0.1 for beating my test set score on English\n",
    "- +0.1 for beating my test set score on Japanese\n",
    "- +0.2 for top English score in 4650\n",
    "- +0.2 for top English score in 7650\n",
    "- +0.2 for top Japanese score in 4650\n",
    "- +0.2 for top Japanese score in 7650\n",
    "\n",
    "If you want to use an external library that is not standard with Python, please ask. For this part of the assignment, we will be more open to the use of 3rd party code, as long as it can be incorporated into your feature function. Libraries that include models that were trained on POS-labeled data will not be allowed. **We must be able to run your code to regenerate your outputs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for my best classification-based tagger, I trained the model for 30 iterations\n",
    "# this took a few minutes\n",
    "theta_best_avp,theta_best_avp_hist =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_feats_competitive_en,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         30,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.904676258993\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_en,\n",
    "                               theta_best_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-best.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_en,\n",
    "                               theta_best_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-best-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-best-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_best_avp_ja,theta_best_avp_hist_ja =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_feats_competitive_ja,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         30,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAFdCAYAAACqzq9RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x247ef940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# as you can see, in this case there was little advantage to training past ten iterations\n",
    "tagger_base.plot_learning_curve(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_hist_ja,\n",
    "                               all_tags_ja);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.94089940563\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-best.ja.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-best-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8788213627992634"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-best-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Structure prediction\n",
    "\n",
    "We now want to incorporate the Viterbi algorithm into the part of speech tagger.\n",
    "\n",
    "If you completed problem set 2, you can do this directly: just replace `tagger_base.classifier_tagger` with `viterbi.viterbi_tagger`. If the feature sets don't use any tag-transition features, then the outputs should be exactly the same.\n",
    "\n",
    "**Deliverable 3.1** Verify that this works, using `features.word_feats`. If your code from pset2 was written correctly, you don't actually have to do anything here. The test `test_viterbi_is_same_d3_1` will test this.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(structure_perceptron);\n",
    "reload(viterbi); # just in case you need to modify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst_classifier,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                3,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst_viterbi,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                                features.word_feats,\n",
    "                                                                viterbi.viterbi_tagger,\n",
    "                                                                3,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_toy_one_inst_classifier == theta_toy_one_inst_viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of using the Viterbi algorithm for structure prediction is that you can use features that look at more than one tag at a time. \n",
    "\n",
    "**Deliverable 3.2** Implement `features.hmm_feats`. This will be very similar to `hmm.hmm_features` from problem set 2, we've only changed some of the constants.\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['They', 'can', 'fish'], ['PRON', 'AUX', 'VERB']),\n",
       " (['the', 'old', 'man', 'the', 'boat'],\n",
       "  ['DET', 'NOUN', 'VERB', 'DET', 'NOUN'])]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('PRON', '--CURR-WORD--', 'They'): 1.0, ('PRON', '--PREV-TAG--', '--START--'): 1.0}\n",
      "{('AUX', '--CURR-WORD--', 'can'): 1.0, ('AUX', '--PREV-TAG--', 'PRON'): 1.0}\n",
      "{('VERB', '--CURR-WORD--', 'fish'): 1.0, ('VERB', '--PREV-TAG--', 'AUX'): 1.0}\n",
      "{('--END--', '--PREV-TAG--', 'VERB'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(features.hmm_feats(toy_data[0][0],'PRON',constants.START_TAG,0))\n",
    "print(features.hmm_feats(toy_data[0][0],'AUX','PRON',1))\n",
    "print(features.hmm_feats(toy_data[0][0],'VERB','AUX',2))\n",
    "print(features.hmm_feats(toy_data[0][0],constants.END_TAG,'VERB',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.3** Evaluate the performance of this structured perceptron on the dev data.\n",
    "\n",
    "This will be slower than the perceptrons that you have trained in the earlier parts of this assignment.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650*)\n",
    "\n",
    "This cell takes three minutes to execute on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#English\n",
    "theta_hmm_sp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.hmm_feats,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         15,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.873301358913\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats,\n",
    "                               theta_hmm_sp,\n",
    "                               all_tags,\n",
    "                               'sp-hmm.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better than many of the fancier feature sets that we tried using the classification-based tagger. \n",
    "\n",
    "That's the power of structured prediction!\n",
    "\n",
    "Now let's try Japanese. This cell takes a little more than two minutes to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Japanese\n",
    "theta_hmm_sp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.hmm_feats,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         15,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.806437142537\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats,\n",
    "                               theta_hmm_sp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'sp-hmm.ja.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvement for Japanese is much more limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bakeoff #2\n",
    "\n",
    "**Deliverable 3.4** Implement the best features that you can for English and Japanese, this time using structured prediction with viterbi tagging.\n",
    "\n",
    "Make sure to save the output in the following files:\n",
    "\n",
    "- **English dev**: `sp-best.preds`\n",
    "- **English test**: `sp-best-te.preds`\n",
    "- **Japanese dev**: `sp-best.ja.preds`\n",
    "- **Japanese test**: `sp-best-te.ja.preds`\n",
    "\n",
    "Grading:\n",
    "- Full credit (0.5 points) for **89.5%** accuracy on English dev set, half credit (0.25 points) for **88.5%** accuracy.\n",
    "- Full credit (0.5 points) for **91%** accuracy on Japanese dev set, half credit (0.25 points) for **90%** accuracy.\n",
    "- +0.1 for beating my test set score on English\n",
    "- +0.1 for beating my test set score on Japanese\n",
    "- +0.2 for top English test set score in 4650\n",
    "- +0.2 for top English test set score in 7650\n",
    "- +0.2 for top Japanese test set score in 4650\n",
    "- +0.2 for top Japanese test set score in 7650\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_best_sp,theta_best_sp_hist =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.hmm_feats_competitive_en,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         30,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23617"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in theta_best_sp.values() if val != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.899880095923\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats_competitive_en,\n",
    "                               theta_best_sp,\n",
    "                               all_tags,\n",
    "                               'sp-best.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_en,\n",
    "                                theta_best_sp,\n",
    "                                all_tags,\n",
    "                                'sp-best-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873505349276274"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'sp-best-te.preds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23617"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in theta_best_sp.values() if val != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_best_sp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.hmm_feats_competitive_ja,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         30,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44220"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features\n",
    "len([val for val in theta_best_sp_ja.values() if val != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.943703039139\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats_competitive_ja,\n",
    "                               theta_best_sp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'sp-best.ja.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_ja,\n",
    "                                theta_best_sp_ja,\n",
    "                                all_tags_ja,\n",
    "                                'sp-best-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.879926335174954"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'sp-best-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(kaggle);\n",
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SUBMIT KAGGLE-avp-bakeoff1-en-test.csv TO https://kaggle.com/join/gtclassificationtaggingen\n",
    "kaggle.kaggle_output(constants.TEST_FILE_HIDDEN,\n",
    "                                tagger_base.classifier_tagger,\n",
    "                                features.word_feats_competitive_en,\n",
    "                                theta_best_avp,\n",
    "                                all_tags,\n",
    "                                'KAGGLE-avp-bakeoff1-en-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUBMIT KAGGLE-avp-bakeoff1-ja-test.csv TO: https://kaggle.com/join/gtclassificationtaggingja\n",
    "kaggle.kaggle_output(constants.JA_TEST_FILE_HIDDEN,\n",
    "                                tagger_base.classifier_tagger,\n",
    "                                features.word_feats_competitive_ja,\n",
    "                                theta_best_avp_ja,\n",
    "                                all_tags_ja,\n",
    "                                'KAGGLE-avp-bakeoff1-ja-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUBMIT KAGGLE-sp-bakeoff2-en-test.csv to https://kaggle.com/join/gt46507650spenpset3\n",
    "kaggle.kaggle_output(constants.TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_en,\n",
    "                                theta_best_sp,\n",
    "                                all_tags,\n",
    "                                'KAGGLE-sp-bakeoff2-en-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUBMIT KAGGLE-sp-bakeoff2-ja-test.csv to https://kaggle.com/join/gtcs46507650pset3ja\n",
    "kaggle.kaggle_output(constants.JA_TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_ja,\n",
    "                                theta_best_sp_ja,\n",
    "                                all_tags_ja,\n",
    "                                'KAGGLE-sp-bakeoff2-ja-test.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
