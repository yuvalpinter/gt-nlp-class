{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 3: Structured Perceptron\n",
    "====================\n",
    "\n",
    "In this problem set, you will implement a sequence labeling algorithm that is near state-of-the-art: structured perceptron. To do this, you will use several functions that you have written earlier, especially Viterbi and averaged perceptron.\n",
    "\n",
    "The problem set is designed to highlight the connection between structured perceptron and classification-based tagging. You will first write most of the pieces that you need while working in the framework of classification-based tagging. Your implementation will take various tagging algorithms as arguments, including both one-word-at-a-time classification based tagging, and Viterbi sequence labeling.\n",
    "\n",
    "One of the main reasons to prefer perceptron over hidden Markov models is the ability to use rich, overlapping features. You will design several feature functions throughout the assignment.\n",
    "\n",
    "Because structure perceptron is slower to train than the hidden Markov model, we will use smaller datasets in this assignment, focusing on sentences that contain the most common POS tags in English and Japanese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import preproc, tagger_base, scorer \n",
    "from gtnlplib import features, viterbi, constants, structure_perceptron\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tags: set([u'ADV', u'NOUN', u'ADP', u'PRON', u'PROPN', u'DET', u'PUNCT', u'VERB', u'AUX', u'ADJ'])\n",
      "Japanese tags: set([u'ADV', u'NOUN', u'PRON', u'DET', u'PUNCT', u'VERB', u'NUM', u'ADJ'])\n"
     ]
    }
   ],
   "source": [
    "## Demo\n",
    "## NOTE! These datafiles are different than in pset2. Don't copy over constants.py from that pset.\n",
    "all_tags = set()\n",
    "for i,(words, tags) in enumerate(preproc.conll_seq_generator(constants.TRAIN_FILE,max_insts=100000)):\n",
    "    for tag in tags:\n",
    "        all_tags.add(tag)\n",
    "print(\"English tags: {}\".format(all_tags))\n",
    "\n",
    "all_tags_ja = set()\n",
    "for i,(words, tags) in enumerate(preproc.conll_seq_generator(constants.JA_TRAIN_FILE,max_insts=100000)):\n",
    "    for tag in tags:\n",
    "        all_tags_ja.add(tag)\n",
    "print(\"Japanese tags: {}\".format(all_tags_ja))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tagging as discriminative classification\n",
    "\n",
    "In pset 2, you performed part-of-speech tagging as generative classification, using Naive Bayes. Now you will perform discriminative classification, using average perceptron.\n",
    "\n",
    "In this section, we are only doing classification-based tagging, but we will write the code in a way that generalizes to Viterbi-based structure prediction. This means that all features are of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.1** Implement `features.word_feats` to output features that are tuples `(y,constants.CURR_WORD_FEAT,w[m])` and `(y,constants.OFFSET)`.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--CURR-WORD--', 'man'): 1.0}\n",
      "{('VERB', '--CURR-WORD--', 'the'): 1.0, ('VERB', '**OFFSET**'): 1.0}\n",
      "{('NOUN', '**OFFSET**'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(features.word_feats(['The','old','man','the','boat'],'NOUN','ADJ',2))\n",
    "print(features.word_feats(['The','old','man','the','boat'],'VERB','NOUN',3))\n",
    "# note that we may need to handle m >= len(tokens)\n",
    "print(features.word_feats(['The','old','man','the','boat'],'NOUN','ADJ',5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.2** Reimplement `tagger_base.classifier_tagger` as follows:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "- List of tokens to tag\n",
    "- Feature function, of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$\n",
    "- Defaultdict of weights\n",
    "- List of all candidate tags\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- List of predicted tags\n",
    "- Score of predicted tag sequence $\\theta \\cdot f(\\boldsymbol{w},\\boldsymbol{y})$\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_clf_hand = defaultdict(float,\n",
    "                             {('NOUN',constants.OFFSET):0.1,\n",
    "                              ('PRON',constants.CURR_WORD_FEAT,'They'):1,\n",
    "                              ('PRON',constants.CURR_WORD_FEAT,'can'):-1,\n",
    "                              ('NOUN',constants.CURR_WORD_FEAT,'fish'):1,\n",
    "                              ('VERB',constants.CURR_WORD_FEAT,'fish'):0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'can', 'fish']\n"
     ]
    }
   ],
   "source": [
    "w = 'They can fish'.split()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'PRON', u'NOUN', u'NOUN'], 2.2)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.classifier_tagger(w,features.word_feats,theta_clf_hand,all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.3** The perceptron update requires computing the difference\n",
    "\n",
    "\\begin{align}\n",
    "& f(\\boldsymbol{w},\\boldsymbol{y}) - f(\\boldsymbol{w},\\hat{\\boldsymbol{y}})\\\\\n",
    "= & \\sum_{m=1}^M f(\\boldsymbol{w},y_m,y_{m-1},m) - f(\\boldsymbol{w},\\hat{y}_m,\\hat{y}_{m-1},m)\n",
    "\\end{align}\n",
    "\n",
    "Implement `tagger_base.compute_features` to compute $f(\\boldsymbol{w},\\boldsymbol{y})$, with the following arguments:\n",
    "\n",
    "- A list of words\n",
    "- A list of tags\n",
    "- A feature function, of the form $f(\\boldsymbol{w},y_m,y_{m-1},m)$.\n",
    "\n",
    "The output should be a dict of features and counts.\n",
    "\n",
    "*Boundary cases*: \n",
    "\n",
    "- When $m=0$, use the special case $y_{-1} = \\text{START}$, using `constants.START_TAG`. *Your current feature function will not test this, because it ignores $y_{m-1}$, but we will test it later*.\n",
    "- When $m=M$, use the special case $y_M = \\text{STOP}$, using `constants.END_TAG`. \n",
    "\n",
    "These boundary cases will be important when you incorporate Viterbi tagging.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('--END--', '**OFFSET**'): 1.0,\n",
       "             ('DET', '**OFFSET**'): 2.0,\n",
       "             ('DET', '--CURR-WORD--', 'the'): 2.0,\n",
       "             ('NOUN', '**OFFSET**'): 2.0,\n",
       "             ('NOUN', '--CURR-WORD--', 'boat'): 1.0,\n",
       "             ('NOUN', '--CURR-WORD--', 'old'): 1.0,\n",
       "             ('VERB', '**OFFSET**'): 1.0,\n",
       "             ('VERB', '--CURR-WORD--', 'man'): 1.0})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.compute_features('the old man the boat'.split(),\n",
    "                            ['DET','NOUN','VERB','DET','NOUN'],\n",
    "                            features.word_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.4**\n",
    "\n",
    "Now you can implement the function `structure_perceptron.sp_update`. \n",
    "\n",
    "This will be very similar to your implementation of `perceptron.perceptron_update` in pset 1, but instead of calling `clf_base.predict`, you should call a function `tagger` which is passed in as an argument.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'PRON', u'NOUN', u'NOUN'], 2.2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.classifier_tagger('They can fish'.split(),\n",
    "                             features.word_feats,\n",
    "                             theta_clf_hand,\n",
    "                             all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update = structure_perceptron.sp_update('They can fish'.split(),\n",
    "                               ['PRON','AUX','VERB'],\n",
    "                               theta_clf_hand,\n",
    "                               features.word_feats,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'NOUN', '**OFFSET**'), -2.0)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('VERB', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for key,val in update.iteritems():\n",
    "    if val != 0:\n",
    "        print(key,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.5**\n",
    "\n",
    "You are now ready to implement `structure_perceptron.estimate_perceptron`.\n",
    "\n",
    "Your implementation will be nearly identical to `perceptron.estimate_perceptron`, except for two things:\n",
    "\n",
    "- The input is now a list of (token-list, tag-list) tuples\n",
    "- Instead of calling `perceptron.perceptron_update`, you will call `structure_perceptron.sp_update`.\n",
    "\n",
    "Other aspects of the implementation, such as weight averaging, should be identical.\n",
    "\n",
    "(*0.7 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "reload(tagger_base)\n",
    "reload(structure_perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_data = [('They can fish'.split(),['PRON','AUX','VERB']),\n",
    "            ('the old man the boat'.split(),['DET','NOUN','VERB','DET','NOUN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst,_ = structure_perceptron.estimate_perceptron(toy_data[:1],\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                1,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--CURR-WORD--', 'They'): 1.0}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.word_feats(toy_data[0][0],'NOUN','IGNORE',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "(('PRON', '--CURR-WORD--', 'They'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -2.999)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "(('PRON', '**OFFSET**'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('VERB', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy_one_inst.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst,_ = structure_perceptron.estimate_perceptron(toy_data[:1],\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                10,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "(('PRON', '--CURR-WORD--', 'They'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -2.999)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "(('PRON', '**OFFSET**'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('VERB', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy_one_inst.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                     features.word_feats,\n",
    "                                                     tagger_base.classifier_tagger,\n",
    "                                                     1, all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'PRON', '--CURR-WORD--', 'boat'), -0.5)\n",
      "(('VERB', '--CURR-WORD--', 'fish'), 1.0)\n",
      "(('NOUN', '**OFFSET**'), -1.999)\n",
      "(('NOUN', '--CURR-WORD--', 'old'), 0.5)\n",
      "((u'NOUN', '--CURR-WORD--', 'They'), -1.0)\n",
      "(('PRON', '**OFFSET**'), -1.5)\n",
      "((u'NOUN', '--CURR-WORD--', 'can'), -1.0)\n",
      "(('VERB', '**OFFSET**'), 1.5)\n",
      "(('AUX', '**OFFSET**'), 1.0)\n",
      "((u'NOUN', '--CURR-WORD--', 'fish'), -1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'old'), -0.5)\n",
      "(('PRON', '--CURR-WORD--', 'They'), 1.0)\n",
      "(('VERB', '--CURR-WORD--', 'man'), 0.5)\n",
      "(('NOUN', '--CURR-WORD--', 'boat'), 0.5)\n",
      "(('AUX', '--CURR-WORD--', 'can'), 1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'the'), -1.0)\n",
      "(('DET', '--CURR-WORD--', 'the'), 1.0)\n",
      "(('DET', '**OFFSET**'), 1.0)\n",
      "((u'PRON', '--CURR-WORD--', 'man'), -0.5)\n"
     ]
    }
   ],
   "source": [
    "for feat,weight in theta_toy.iteritems():\n",
    "    if weight != 0:\n",
    "        print(feat,weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 1.6 ** Let's train this tagger and evaluate it.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = [inst for inst in preproc.conll_seq_generator(constants.TRAIN_FILE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3531"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes 30 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_avp,theta_hist = structure_perceptron.estimate_perceptron(training_set,\n",
    "                                                       features.word_feats,\n",
    "                                                       tagger_base.classifier_tagger,\n",
    "                                                       20,\n",
    "                                                       all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129496402877698"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-020d7712d1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you can't run this line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-te.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Yuval\\git\\gt-nlp-class\\psets\\ps3\\gtnlplib\\scorer.py\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you can't run this line\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how accuracy improved over training. \n",
    "You can use this function elsewhere in the notebook if you'd like to see the progress of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6c39c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagger_base.plot_learning_curve(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_hist,\n",
    "                               all_tags);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These accuracies are not directly comparable with your HMM accuracies from pset2, since we are using a different dataset.\n",
    "\n",
    "Let's see how many features are active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active features: 19265\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of active features: %d\"%len([val for val in theta_avp.values() if val != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.7** Now try it on Japanese. \n",
    "\n",
    "(*0.5 points for 4650 / 0.25 points for 7650*)\n",
    "\n",
    "As before, 4650 students can opt in to 7650 grading by doing the 7650 problems.\n",
    "\n",
    "Please set the `GRADING` variable in `constants.py` to the appropriate grading scheme. Note that CS7650 students must be graded by the CS7650 rubric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_ja = [inst for inst in preproc.conll_seq_generator(constants.JA_TRAIN_FILE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes approximately 40 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_avp_ja,theta_hist_ja =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.790288213524728"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats,\n",
    "                               theta_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.8 (for 7650)** As you can see from the cells here, this tagging model is less accurate for Japanese than it is for English. Why might that be? (I'm looking for an explanation that is based on quantitative facts about the datasets.) Put your answer in `text-answers.md`.\n",
    "\n",
    "(*0.5 points for 7650, optional for 4650*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active features: 38401\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of active features: %d\"%len([val for val in theta_avp_ja.values() if val != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3531, 2655)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set), len(training_set_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Better features\n",
    "\n",
    "One simple way to improve tagging is to add better features to the classification-based tagger. \n",
    "\n",
    "**Deliverable 2.1** Let's start by adding features that include the final two characters of each word as an additional, suffix feature. Do this by implementing `word_suff_features` in `features.py`.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(constants)\n",
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('DET', '--CURR-WORD--', 'The'): 1.0, ('DET', '**OFFSET**'): 1.0, ('DET', '--SUFFIX--', 'he'): 1.0}\n",
      "{('NOUN', '--SUFFIX--', 'ld'): 1.0, ('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--CURR-WORD--', 'old'): 1.0}\n",
      "{('NOUN', '**OFFSET**'): 1.0, ('NOUN', '--SUFFIX--', 'a'): 1.0, ('NOUN', '--CURR-WORD--', 'a'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(features.word_suff_feats(['The','old','man','a','boat'],'DET','ADJ',0))\n",
    "print(features.word_suff_feats(['The','old','man','a','boat'],'NOUN','DET',1))\n",
    "print(features.word_suff_feats(['The','old','man','a','boat'],'NOUN','ADJ',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.2** Let's see whether this improves accuracy.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650. Includes both English and Japanese evaluations.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes 50 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_suff_avp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_suff_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8439248601119105"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-0c0f5fa3ae5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# you cannot run this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'avp-words-suff-te.preds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Yuval\\git\\gt-nlp-class\\psets\\ps3\\gtnlplib\\scorer.py\u001b[0m in \u001b[0;36mget_confusion\u001b[0;34m(keyfilename, responsefilename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponsefilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/en-ud-simpler-test.conllu'"
     ]
    }
   ],
   "source": [
    "# you cannot run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-suff-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 3% better than the word-only feature set! That's pretty good for adding a single feature template. Now let's try Japanese. \n",
    "\n",
    "The cell below takes 45 seconds to execute on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_suff_avp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_suff_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8816866659190311"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-suff.ja.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10% better on Japanese! Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_suff_feats,\n",
    "                               theta_suff_avp_ja,\n",
    "                               all_tags,\n",
    "                               'avp-words-suff-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-suff-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.3 (7650)** Briefly explain why you think suffix features are so helpful in Japanese. No prior Japanese knowledge is assumed! You may want to look at the raw data, and consult some resources about Japanese that you can find from a quick Google search. Put your answer in `text-answers.md`.\n",
    "\n",
    "(*0.5 points for 7650, optional for 4650*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.4** Now implement word neighbor features. These are features that should link a given tag to the words than come before and after it. Implement this function in `features.word_neighbor_feats`, and make sure it gives the same results as in the example cell below. Pay attention to the boundary case at the end. See `constants.PRE_START_TOKEN` and `constants.POST_END_TOKEN`.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(constants)\n",
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TAG', '--CURR-WORD--', 'The'): 1.0\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--PREV-WORD--', '[[START]]'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'old'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'man'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'The'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'old'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'a'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'man'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'old'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'a'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'man'): 1.0\n",
      "('TAG', '--NEXT-WORD--', 'boat'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--NEXT-WORD--', '[[END]]'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'a'): 1.0\n",
      "('TAG', '--CURR-WORD--', 'boat'): 1.0\n",
      "\n",
      "('TAG', '**OFFSET**'): 1.0\n",
      "('TAG', '--PREV-WORD--', 'boat'): 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in xrange(6):\n",
    "    feats = features.word_neighbor_feats(['The','old','man','a','boat'],'TAG','IGNORE',m)\n",
    "    for feat,count in feats.iteritems():\n",
    "        print('{}: {}'.format(feat,count))\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.5** Let's try it, in both English and Japanese.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650*)\n",
    "\n",
    "The code below takes 60 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_neighbor_avp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_neighbor_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577138289368506"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_neighbor_feats,\n",
    "                               theta_neighbor_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-neighbor.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better for English than the suffix features! Let's try Japanese.\n",
    "\n",
    "The code below takes 60 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_neighbor_avp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_neighbor_feats,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         20,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8020634742626443"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_neighbor_feats,\n",
    "                               theta_neighbor_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-neighbor.ja.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neighbor features don't help nearly as much in Japanese, compared to the impact they make in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAKEOFF #1\n",
    "\n",
    "**Deliverable 2.6** Implement the best features that you can for English and Japanese.\n",
    "You can use the same features for each, or you can use different features.\n",
    "You can also train the model longer, if you think that will help.\n",
    "\n",
    "Make sure to save the output in the following files:\n",
    "\n",
    "- **English dev**: `avp-best.preds`\n",
    "- **English test**: `avp-best-te.preds`\n",
    "- **Japanese dev**: `avp-best.ja.preds`\n",
    "- **Japanese test**: `avp-best-te.ja.preds`\n",
    "\n",
    "Grading:\n",
    "- Full credit (0.5 pts) for **88%** accuracy on English dev set, half credit (0.25 pts) for **87%** dev set accuracy.\n",
    "- Full credit (0.5 pts) for **90%** accuracy on Japanese dev set, half credit (0.25 pts) for **89%** dev set accuracy.\n",
    "- +0.1 for beating my test set score on English\n",
    "- +0.1 for beating my test set score on Japanese\n",
    "- +0.2 for top English score in 4650\n",
    "- +0.2 for top English score in 7650\n",
    "- +0.2 for top Japanese score in 4650\n",
    "- +0.2 for top Japanese score in 7650\n",
    "\n",
    "If you want to use an external library that is not standard with Python, please ask. For this part of the assignment, we will be more open to the use of 3rd party code, as long as it can be incorporated into your feature function. Libraries that include models that were trained on POS-labeled data will not be allowed. **We must be able to run your code to regenerate your outputs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for my best classification-based tagger, I trained the model for 30 iterations\n",
    "# this took a few minutes\n",
    "theta_best_avp,theta_best_avp_hist =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.word_feats_competitive_en,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         30,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.894884092726\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_en,\n",
    "                               theta_best_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-best.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_en,\n",
    "                               theta_best_avp,\n",
    "                               all_tags,\n",
    "                               'avp-words-best-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873505349276274"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'avp-words-best-te.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_best_avp_ja,theta_best_avp_hist_ja =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.word_feats_competitive_ja,\n",
    "                                         tagger_base.classifier_tagger,\n",
    "                                         30,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFdCAYAAABW24SbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x489f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# as you can see, in this case there was little advantage to training past ten iterations\n",
    "tagger_base.plot_learning_curve(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_hist_ja,\n",
    "                               all_tags_ja);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.920040372323\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-best.ja.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                               tagger_base.classifier_tagger,\n",
    "                               features.word_feats_competitive_ja,\n",
    "                               theta_best_avp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'avp-words-best-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8788213627992634"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'avp-words-best-te.ja.preds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Structure prediction\n",
    "\n",
    "We now want to incorporate the Viterbi algorithm into the part of speech tagger.\n",
    "\n",
    "If you completed problem set 2, you can do this directly: just replace `tagger_base.classifier_tagger` with `viterbi.viterbi_tagger`. If the feature sets don't use any tag-transition features, then the outputs should be exactly the same.\n",
    "\n",
    "**Deliverable 3.1** Verify that this works, using `features.word_feats`. If your code from pset2 was written correctly, you don't actually have to do anything here. The test `test_viterbi_is_same_d3_1` will test this.\n",
    "\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(structure_perceptron);\n",
    "reload(viterbi); # just in case you need to modify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst_classifier,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                                features.word_feats,\n",
    "                                                                tagger_base.classifier_tagger,\n",
    "                                                                3,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_toy_one_inst_viterbi,_ = structure_perceptron.estimate_perceptron(toy_data,\n",
    "                                                                features.word_feats,\n",
    "                                                                viterbi.viterbi_tagger,\n",
    "                                                                3,\n",
    "                                                                all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_toy_one_inst_classifier == theta_toy_one_inst_viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of using the Viterbi algorithm for structure prediction is that you can use features that look at more than one tag at a time. \n",
    "\n",
    "**Deliverable 3.2** Implement `features.hmm_feats`. This will be very similar to `hmm.hmm_features` from problem set 2, we've only changed some of the constants.\n",
    "(*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['They', 'can', 'fish'], ['PRON', 'AUX', 'VERB']),\n",
       " (['the', 'old', 'man', 'the', 'boat'],\n",
       "  ['DET', 'NOUN', 'VERB', 'DET', 'NOUN'])]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('PRON', '--CURR-WORD--', 'They'): 1.0, ('PRON', '--PREV-TAG--', '--START--'): 1.0}\n",
      "{('AUX', '--CURR-WORD--', 'can'): 1.0, ('AUX', '--PREV-TAG--', 'PRON'): 1.0}\n",
      "{('VERB', '--CURR-WORD--', 'fish'): 1.0, ('VERB', '--PREV-TAG--', 'AUX'): 1.0}\n",
      "{('--END--', '--PREV-TAG--', 'VERB'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(features.hmm_feats(toy_data[0][0],'PRON',constants.START_TAG,0))\n",
    "print(features.hmm_feats(toy_data[0][0],'AUX','PRON',1))\n",
    "print(features.hmm_feats(toy_data[0][0],'VERB','AUX',2))\n",
    "print(features.hmm_feats(toy_data[0][0],constants.END_TAG,'VERB',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.3** Evaluate the performance of this structured perceptron on the dev data.\n",
    "\n",
    "This will be slower than the perceptrons that you have trained in the earlier parts of this assignment.\n",
    "\n",
    "(*0.5 points for 4650, 0.25 points for 7650*)\n",
    "\n",
    "This cell takes three minutes to execute on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#English\n",
    "theta_hmm_sp,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.hmm_feats,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         15,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.873301358913\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats,\n",
    "                               theta_hmm_sp,\n",
    "                               all_tags,\n",
    "                               'sp-hmm.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better than many of the fancier feature sets that we tried using the classification-based tagger. \n",
    "\n",
    "That's the power of structured prediction!\n",
    "\n",
    "Now let's try Japanese. This cell takes a little more than two minutes to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Japanese\n",
    "theta_hmm_sp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.hmm_feats,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         15,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.806437142537\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats,\n",
    "                               theta_hmm_sp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'sp-hmm.ja.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvement for Japanese is much more limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bakeoff #2\n",
    "\n",
    "**Deliverable 3.4** Implement the best features that you can for English and Japanese, this time using structured prediction with viterbi tagging.\n",
    "\n",
    "Make sure to save the output in the following files:\n",
    "\n",
    "- **English dev**: `sp-best.preds`\n",
    "- **English test**: `sp-best-te.preds`\n",
    "- **Japanese dev**: `sp-best.ja.preds`\n",
    "- **Japanese test**: `sp-best-te.ja.preds`\n",
    "\n",
    "Grading:\n",
    "- Full credit (0.5 points) for **89.5%** accuracy on English dev set, half credit (0.25 points) for **88.5%** accuracy.\n",
    "- Full credit (0.5 points) for **91%** accuracy on Japanese dev set, half credit (0.25 points) for **90%** accuracy.\n",
    "- +0.1 for beating my test set score on English\n",
    "- +0.1 for beating my test set score on Japanese\n",
    "- +0.2 for top English test set score in 4650\n",
    "- +0.2 for top English test set score in 7650\n",
    "- +0.2 for top Japanese test set score in 4650\n",
    "- +0.2 for top Japanese test set score in 7650\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n"
     ]
    }
   ],
   "source": [
    "theta_best_sp,theta_best_sp_hist =\\\n",
    "structure_perceptron.estimate_perceptron(training_set,\n",
    "                                         features.hmm_feats_competitive_en,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         30,\n",
    "                                         all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43028"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in theta_best_sp.values() if val != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dev set\n",
      "0.903477218225\n"
     ]
    }
   ],
   "source": [
    "print('EN dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats_competitive_en,\n",
    "                               theta_best_sp,\n",
    "                               all_tags,\n",
    "                               'sp-best.preds')\n",
    "print(dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_base.apply_tagging_model(constants.TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_en,\n",
    "                                theta_best_sp,\n",
    "                                all_tags,\n",
    "                                'sp-best-te.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873505349276274"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.TEST_FILE,'sp-best-te.preds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43028"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in theta_best_sp.values() if val != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n"
     ]
    }
   ],
   "source": [
    "theta_best_sp_ja,_ =\\\n",
    "structure_perceptron.estimate_perceptron(training_set_ja,\n",
    "                                         features.hmm_feats_competitive_ja,\n",
    "                                         viterbi.viterbi_tagger,\n",
    "                                         30,\n",
    "                                         all_tags_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67002"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features\n",
    "len([val for val in theta_best_sp_ja.values() if val != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA dev set\n",
      "0.921273971067\n"
     ]
    }
   ],
   "source": [
    "print('JA dev set')\n",
    "dev_results = tagger_base.eval_tagging_model(constants.JA_DEV_FILE,\n",
    "                               viterbi.viterbi_tagger,\n",
    "                               features.hmm_feats_competitive_ja,\n",
    "                               theta_best_sp_ja,\n",
    "                               all_tags_ja,\n",
    "                               'sp-best.ja.preds')\n",
    "print(dev_results)\n",
    "tagger_base.apply_tagging_model(constants.JA_TEST_FILE_HIDDEN,\n",
    "                                viterbi.viterbi_tagger,\n",
    "                                features.hmm_feats_competitive_ja,\n",
    "                                theta_best_sp_ja,\n",
    "                                all_tags_ja,\n",
    "                                'sp-best-te.ja.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.879926335174954"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can't run this\n",
    "scorer.accuracy(scorer.get_confusion(constants.JA_TEST_FILE,'sp-best-te.ja.preds'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
